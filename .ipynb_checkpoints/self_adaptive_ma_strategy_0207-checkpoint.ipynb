{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#coding: utf-8\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def market_efficiency(close_price):\n",
    "    numerator=np.abs(close_price[-1]-close_price[0])\n",
    "    denominator=np.sum(np.abs(np.diff(close_price)))\n",
    "    return numerator/denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sama(close_price,width):\n",
    "    c=0.1\n",
    "    d=0.9\n",
    "    sigma=3.\n",
    "    N=len(close_price)\n",
    "    ma=np.zeros_like(close_price)\n",
    "    for i in range(width-1,N):\n",
    "        p=close_price[i-width+1:i]\n",
    "        e=market_efficiency(p)\n",
    "        a=(c+d*e)**sigma\n",
    "        ma[i]=a*close_price[i]+(1-a)*ma[i-1]\n",
    "    return ma\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def execute(category):\n",
    "    df=pd.read_csv('/Users/liyuefan/Documents/gtja/%sFI_0112.csv'%category,encoding='gbk')\n",
    "\n",
    "\n",
    "\n",
    "    df['update_date']=pd.to_datetime(df['update_date'])\n",
    "    df['close_yes']=df['close'].shift(1)\n",
    "\n",
    "    close_yes=np.array(df['close_yes'])\n",
    "    df['ma10']=sama(close_yes,10)\n",
    "    df['ma20']=sama(close_yes,20)\n",
    "    df['ma30']=sama(close_yes,60)\n",
    "    df['ma60']=sama(close_yes,100)\n",
    "    df['ma100']=sama(close_yes,200)\n",
    "\n",
    "\n",
    "    df['close_return_yes']=np.log(df['close_yes'])\n",
    "    df['close_return_yes']=df['close_return_yes'].diff()\n",
    "    df['volatility_20']=pd.rolling_std(df['close_return_yes'],20)\n",
    "    df['volatility_60']=pd.rolling_std(df['close_return_yes'],60)\n",
    "    df['volatility_100']=pd.rolling_std(df['close_return_yes'],100)\n",
    "    df['volatility_200']=pd.rolling_std(df['close_return_yes'],200)\n",
    "\n",
    "\n",
    "    def sig(x1,p):\n",
    "        if p<x1:\n",
    "            return -1\n",
    "        elif p>x1:\n",
    "            return 1\n",
    "        else:\n",
    "            return np.nan\n",
    "\n",
    "#     df['stop_ma10']=map(sig,df['ma10'],df['close'])\n",
    "    df['p_ma10']=map(sig,df['ma20'],df['close'])\n",
    "    df['p_ma30']=map(sig,df['ma30'],df['close'])\n",
    "    df['p_ma60']=map(sig,df['ma60'],df['close'])\n",
    "    df['p_ma100']=map(sig,df['ma100'],df['close'])\n",
    "\n",
    "\n",
    "    def dir(x):\n",
    "        if x>0:\n",
    "            return 1\n",
    "        elif x<0:\n",
    "            return -1\n",
    "        else:\n",
    "            return 0\n",
    "    df=df.sort('update_date')\n",
    "\n",
    "\n",
    "    df['p_ma10']=df['p_ma10'].fillna(method='ffill')\n",
    "    df['p_ma30']=df['p_ma30'].fillna(method='ffill')\n",
    "    df['p_ma60']=df['p_ma60'].fillna(method='ffill')\n",
    "    df['p_ma100']=df['p_ma100'].fillna(method='ffill')\n",
    "\n",
    "    df=df.dropna(axis=0)\n",
    "\n",
    "    pos_mat=df.loc[:,['p_ma10','p_ma30','p_ma60','p_ma100','volatility_20','volatility_60','volatility_100','volatility_200']]\n",
    "    pos_mat=pos_mat.as_matrix()\n",
    "\n",
    "    N=pos_mat.shape[0]\n",
    "    p=np.zeros(N)\n",
    "    temp_tag=0\n",
    "    for i in range(N):\n",
    "        if np.isnan(pos_mat[i,3])==True:\n",
    "            p[i]=0\n",
    "        else:\n",
    "            if pos_mat[i,0]>0:\n",
    "                temp_tag=1\n",
    "                dis_20=pos_mat[i,4]/np.mean(pos_mat[:i,4])\n",
    "                dis_60=pos_mat[i,5]/np.mean(pos_mat[:i,5])\n",
    "                dis_100=pos_mat[i,6]/np.mean(pos_mat[:i,6])\n",
    "                dis_200=pos_mat[i,7]/np.mean(pos_mat[:i,7])\n",
    "                p[i]=0.4/dis_20\n",
    "                if pos_mat[i,3]>0:\n",
    "                    p[i]=(0.4/dis_20+0.3/dis_60+0.2/dis_100+0.1/dis_200)\n",
    "                elif pos_mat[i,2]>0:\n",
    "                    p[i]=(0.4/dis_20+0.3/dis_60+0.2/dis_100)\n",
    "                elif pos_mat[i,1]>0:\n",
    "                    p[i]=(0.4/dis_20+0.3/dis_60)\n",
    "\n",
    "            elif pos_mat[i,0]<0:\n",
    "                temp_tag=-1\n",
    "                dis_20=pos_mat[i,4]/np.mean(pos_mat[:i,4])\n",
    "                dis_60=pos_mat[i,5]/np.mean(pos_mat[:i,5])\n",
    "                dis_100=pos_mat[i,6]/np.mean(pos_mat[:i,6])\n",
    "                dis_200=pos_mat[i,7]/np.mean(pos_mat[:i,7])\n",
    "                p[i]=-0.4/dis_20\n",
    "                if pos_mat[i,3]<0:\n",
    "                    p[i]=(-0.4/dis_20-0.3/dis_60-0.2/dis_100-0.1/dis_200)\n",
    "                elif pos_mat[i,2]<0:\n",
    "                    p[i]=(-0.4/dis_20-0.3/dis_60-0.2/dis_100)\n",
    "                elif pos_mat[i,1]<0:\n",
    "                    p[i]=(-0.4/dis_20-0.3/dis_60)\n",
    "\n",
    "#             elif temp_tag>0 and pos_mat[i,8]==-1:\n",
    "#                 temp_tag=0\n",
    "#                 print 'stop'\n",
    "#                 p[i]=0\n",
    "#             elif temp_tag<0 and pos_mat[i,8]==1:\n",
    "#                 temp_tag=0\n",
    "#                 print 'stop'\n",
    "#                 p[i]=0\n",
    "            else:\n",
    "                p[i]=np.nan\n",
    "\n",
    "\n",
    "\n",
    "    df['position']=p\n",
    "    df['position']=df['position'].fillna(method='ffill')\n",
    "\n",
    "    df['close_return']=np.log(df['close'])\n",
    "    df['close_return']=df['close_return'].diff()\n",
    "\n",
    "    df['position']=df['position'].shift(2)\n",
    "\n",
    "\n",
    "\n",
    "    df['daily_return']=df['position']*df['close_return']\n",
    "    \n",
    "    \n",
    "    close_return=np.array(df['daily_return'])\n",
    "    position=np.array(df['position'])\n",
    "    for i in range(1,len(position)):\n",
    "        if position[i]!=position[i-1]:\n",
    "            close_return[i-1]=close_return[i-1]-1./10000\n",
    "            close_return[i]=close_return[i]-1./10000\n",
    "        else:\n",
    "            pass\n",
    "    df['daily_return']=close_return\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    df['cum_return']=df['daily_return'].cumsum()\n",
    "\n",
    "    df.index=[df['update_date']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def portfolio(comp1,comp2):\n",
    "    if type(comp1)==str and type(comp2)==str:\n",
    "        comp1=execute(comp1)\n",
    "        comp2=execute(comp2)\n",
    "    else:\n",
    "        comp1=comp1\n",
    "        comp2=comp2\n",
    "    comp1=comp1.rename(columns={'daily_return':'daily_return_1','close_return':'close_return_1'})\n",
    "    comp2=comp2.rename(columns={'daily_return':'daily_return_2','close_return':'close_return_2'})\n",
    "    t=pd.merge(comp1,comp2,on='update_date',how='inner')\n",
    "\n",
    "    tt=t.loc[:,['update_date','daily_return_1','daily_return_2','close_return_1','close_return_2']]\n",
    "\n",
    "    tt['portfolio_return']=0.5*tt['daily_return_1']+0.5*tt['daily_return_2']\n",
    "    tt['close_return']=0.5*tt['close_return_1']+0.5*tt['close_return_2']\n",
    "\n",
    "    tt['port_cum_return']=tt['portfolio_return'].cumsum()\n",
    "    tt['port_cummax']=tt['port_cum_return'].cummax()\n",
    "    tt['port_drawdown']=tt['port_cum_return']-tt['port_cummax']\n",
    "    tt['update_date']=pd.to_datetime(tt['update_date'])\n",
    "    return tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def port_port(port1,port2):\n",
    "    port1=port1.drop(['daily_return_1','daily_return_2','close_return_1','close_return_2'],axis=1)\n",
    "    port2=port2.drop(['daily_return_1','daily_return_2','close_return_1','close_return_2'],axis=1)\n",
    "    port1=port1.rename(columns={'portfolio_return':'daily_return_1','close_return':'close_return_1'})\n",
    "    port2=port2.rename(columns={'portfolio_return':'daily_return_2','close_return':'close_return_2'})\n",
    "    \n",
    "    t=pd.merge(port1,port2,on='update_date',how='inner')\n",
    "\n",
    "    tt=t.loc[:,['update_date','daily_return_1','daily_return_2','close_return_1','close_return_2']]\n",
    "    \n",
    "    tt['portfolio_return']=0.5*tt['daily_return_1']+0.5*tt['daily_return_2']\n",
    "    tt['close_return']=0.5*tt['close_return_1']+tt['close_return_2']\n",
    "    \n",
    "    tt['port_cum_return']=tt['portfolio_return'].cumsum()\n",
    "    tt['port_cummax']=tt['port_cum_return'].cummax()\n",
    "    tt['port_drawdown']=tt['port_cum_return']-tt['port_cummax']\n",
    "    return tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def comp_portfolio(asset_pool):\n",
    "    import itertools\n",
    "    import scipy as sp\n",
    "    import scipy.stats as stats\n",
    "    all_assets=pd.DataFrame(columns=['update_date'])\n",
    "    for a in asset_pool:\n",
    "        tmp=execute(a)\n",
    "#         tmp=tmp.loc[:,['update_date','daily_return']]\n",
    "        tmp=tmp.loc[:,['update_date','close_return']] \n",
    "#         tmp=tmp.rename(columns={'daily_return':'%s'%a})\n",
    "        tmp=tmp.rename(columns={'close_return':'%s'%a})\n",
    "        all_assets=pd.merge(all_assets,tmp,on='update_date',how='outer')\n",
    "    all_assets['update_date']=pd.to_datetime(all_assets['update_date'])\n",
    "    all_assets['year']=all_assets['update_date'].apply(lambda x: x.year)\n",
    "    selected_port_dict={}\n",
    "    for year in pd.unique(all_assets['year']):\n",
    "        tmp=all_assets[all_assets['year']==year]\n",
    "        tmp=tmp.dropna(how='all',axis=1)\n",
    "        col_list=[col for col in tmp.columns if col!='update_date' and col!='year']\n",
    "        corr_dict={}\n",
    "        for item in itertools.product(col_list,col_list):\n",
    "            if item[0]!=item[1]:\n",
    "                cor_mat=tmp.loc[:,item]\n",
    "                cor_mat=cor_mat.dropna(axis=0)\n",
    "                cor_mat=cor_mat.as_matrix()\n",
    "#                 corr=sp.corrcoef(cor_mat.T)\n",
    "                corr,p=stats.pearsonr(cor_mat[:,0],cor_mat[:,1])\n",
    "#                 corr=corr[0,1]\n",
    "                if p>0.01:\n",
    "                    corr_dict[item]=np.abs(corr)\n",
    "                else:\n",
    "                    corr_dict[item]=np.nan\n",
    "            else:\n",
    "                pass\n",
    "        corr_dict_items=filter(lambda x:np.isnan(x[1])==False,corr_dict.items())\n",
    "        if len(corr_dict_items)>=4:\n",
    "            selected_port=[item for item in sorted(corr_dict_items, key=lambda d:d[1],reverse=False)][0:3]\n",
    "            selected_port_1=selected_port[0]\n",
    "            selected_list=[x for x in selected_port_1[0]]\n",
    "            for i in range(len(selected_port)):\n",
    "                tmp_1=selected_port[i][0]\n",
    "                if tmp_1[0] not in selected_list or tmp_1[1] not in selected_list:\n",
    "                    selected_port_2=selected_port[i]\n",
    "                else:\n",
    "                    pass\n",
    "            selected_port_dict[year+1]=[selected_port_1,selected_port_2]\n",
    "        \n",
    "            print year+1, selected_port_1, '%.3f'%selected_port_dict[year+1][0][1]\n",
    "            print year+1, selected_port_2, '%.3f'%selected_port_dict[year+1][1][1]\n",
    "        #如果无法通过相关性检验，则选择波动性最低的几个品种\n",
    "        else:\n",
    "            tmp_=tmp.drop(['update_date','year'],axis=1)\n",
    "            \n",
    "            std_list=np.std(tmp_)\n",
    "            std_list=std_list.to_dict()\n",
    "            std_list=filter(lambda x:np.isnan(x[1])==False,std_list.items())\n",
    "            if len(std_list)>=4:\n",
    "                selected_port=[item for item in sorted(std_list,key=lambda d:d[1],reverse=False)][0:4]\n",
    "                selected_port_1=((selected_port[0][0],selected_port[1][0]),0)\n",
    "                selected_port_2=((selected_port[2][0],selected_port[3][0]),0)\n",
    "                selected_port_dict[year+1]=[selected_port_1,selected_port_2]\n",
    "                print 'std min: ',year+1, selected_port_1#, '%.3f'%selected_port_dict[year+1][0][1]\n",
    "                print 'std min: ',year+1, selected_port_2#, '%.3f'%selected_port_dict[year+1][1][1]\n",
    "            #如果还不行，那就直接按照过去一年的累积收益率高低进行排序，选择去年收益率最低的做一个反转策略\n",
    "            else:\n",
    "            \n",
    "            \n",
    "            \n",
    "                mean_list=np.abs(np.mean(tmp_))\n",
    "                mean_list=mean_list.to_dict()\n",
    "                mean_list=filter(lambda x:np.isnan(x[1])==False,mean_list.items())\n",
    "\n",
    "\n",
    "                if len(mean_list)>=4:\n",
    "                    selected_port=[item for item in sorted(mean_list,key=lambda d:d[1],reverse=False)][0:4]\n",
    "                    selected_port_1=((selected_port[0][0],selected_port[1][0]),0)\n",
    "                    selected_port_2=((selected_port[2][0],selected_port[3][0]),0)\n",
    "                    selected_port_dict[year+1]=[selected_port_1,selected_port_2]\n",
    "                    print 'mean reverse: ',year+1, selected_port_1#, '%.3f'%selected_port_dict[year+1][0][1]\n",
    "                    print 'mean reverse: ',year+1, selected_port_2#, '%.3f'%selected_port_dict[year+1][1][1]\n",
    "                #如果这样都不行的话...\n",
    "                else:\n",
    "                    pass\n",
    "                    print u'另请高明：',year+1\n",
    "                    \n",
    "\n",
    "                \n",
    "            \n",
    "    return selected_port_dict\n",
    "    \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "asset_pool=['CU','ZN','PB','AL','NI','I','JM','J','WH','ZC','Y','TA','SR','RU','RM','P','M','C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=comp_portfolio(asset_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mixed_port=pd.DataFrame()\n",
    "for item in a.items():\n",
    "    print item[0]\n",
    "\n",
    "    \n",
    "#####如果取前两对############\n",
    "    print item\n",
    "    tmp_1=portfolio(item[1][0][0][0],item[1][0][0][1])\n",
    "    tmp_1['update_date']=pd.to_datetime(tmp_1['update_date'])\n",
    "    tmp_1=tmp_1[tmp_1['update_date'].apply(lambda x:x.year)==item[0]]\n",
    "    tmp_2=portfolio(item[1][1][0][0],item[1][1][0][1])\n",
    "    tmp_2['update_date']=pd.to_datetime(tmp_2['update_date'])\n",
    "    tmp_2=tmp_2[tmp_2['update_date'].apply(lambda x:x.year)==item[0]]\n",
    "    tmp=port_port(tmp_1,tmp_2)\n",
    "\n",
    "#####如果只取一对###########\n",
    "#     tmp=portfolio(item[1][0][0][0],item[1][0][0][1])\n",
    "#     tmp['update_date']=pd.to_datetime(tmp['update_date'])\n",
    "#     tmp=tmp[tmp['update_date'].apply(lambda x:x.year)==item[0]]\n",
    "##########################\n",
    "    \n",
    "    if len(tmp)>0:\n",
    "        tmp['update_date']=pd.to_datetime(tmp['update_date'])\n",
    "        tmp=tmp[tmp['update_date'].apply(lambda x:x.year)==item[0]]\n",
    "        tmp=tmp.loc[:,['update_date','portfolio_return','close_return']]\n",
    "        mixed_port=mixed_port.append(tmp)\n",
    "    else:\n",
    "        print 'no data!'\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mixed_port=mixed_port.sort('update_date')\n",
    "mixed_port['cum_return']=mixed_port['portfolio_return'].cumsum()\n",
    "mixed_port['benchmark']=mixed_port['close_return'].cumsum()\n",
    "mixed_port['cum_max']=mixed_port['cum_return'].cummax()\n",
    "mixed_port['drawdown']=mixed_port['cum_return']-mixed_port['cum_max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.min(mixed_port['drawdown']/(1+mixed_port['cum_max']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(mixed_port['update_date'],mixed_port['cum_return'])\n",
    "plt.plot(mixed_port['update_date'],mixed_port['benchmark'],label='benchmark')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mixed_port['year']=mixed_port['update_date'].apply(lambda x: x.year)\n",
    "each_year_return=mixed_port.groupby(['year']).portfolio_return.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "each_year_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(np.mean(mixed_port['portfolio_return'])*252)/(np.std(mixed_port['portfolio_return'])*np.sqrt(252))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(mixed_port['portfolio_return'])*252"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
