{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#coding: utf-8\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import urllib2\n",
    "import bs4\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "from sqlalchemy import create_engine\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def execute(page_number):\n",
    "    url='https://www.quantnet.com/tracker/?page=%s'%page_number\n",
    "    req=urllib2.urlopen(url)\n",
    "    page=req.read()\n",
    "    page=bs4.BeautifulSoup(page)\n",
    "    p1=page.find_all(class_='applicationListItem')\n",
    "    total=[]\n",
    "    for r in p1:\n",
    "        cd=r.children\n",
    "        tmp=[]\n",
    "        for k in cd:\n",
    "            if len(k)>1:\n",
    "                ks=k.stripped_strings\n",
    "\n",
    "                for ik in ks:\n",
    "                    tmp.append(ik)\n",
    "        tmp_=[]\n",
    "\n",
    "        tmp_.append(tmp[0])\n",
    "\n",
    "        tmp[1]=tmp[1].replace('(','').replace(')','')\n",
    "        tmp_.append(tmp[1])\n",
    "\n",
    "        tmp_.append(tmp[2])\n",
    "        \n",
    "#         tmp[5]=float(tmp[5])\n",
    "        tmp_.append(tmp[5])\n",
    "    \n",
    "        \n",
    "        try:\n",
    "            tmp[6]=int(tmp[6])\n",
    "            tmp_.append(tmp[6])\n",
    "        except:\n",
    "            tmp_.append(np.nan)\n",
    "        \n",
    "        try:\n",
    "            tmp[7]=int(tmp[7])\n",
    "            tmp_.append(tmp[7])\n",
    "        except:\n",
    "            tmp_.append(np.nan)\n",
    "\n",
    "            \n",
    "        try:\n",
    "            tmp[8]=float(tmp[8])\n",
    "            tmp_.append(tmp[8])\n",
    "        except:\n",
    "            tmp_.append(np.nan)\n",
    "        \n",
    "        tmp[9]=pd.to_datetime(tmp[9])\n",
    "        tmp_.append(tmp[9])\n",
    "        if tmp[10]==u'Pending' or tmp[10]==u'Waitlist' and tmp[11][0]!='(':\n",
    "            tmp_.append(pd.to_datetime('1970-01-01'))\n",
    "            tmp_.append(tmp[10])\n",
    "            tmp[11]=tmp[11].split(': ')[1]\n",
    "            tmp[11]=tmp[11].replace(')','')\n",
    "            tmp[11]=pd.to_datetime(tmp[9])+np.timedelta64(tmp[11],'D')\n",
    "\n",
    "            tmp_.append(tmp[11])\n",
    "\n",
    "\n",
    "            tmp_.append(tmp[16])\n",
    "        \n",
    "        elif tmp[10]==u'Pending' or tmp[10]==u'Waitlist' and tmp[11][0:2]=='(D':\n",
    "            tmp_.append(pd.to_datetime('1970-01-01'))\n",
    "            tmp_.append(tmp[10])\n",
    "            tmp[11]=tmp[11].split(': ')[1]\n",
    "            tmp[11]=tmp[11].replace(')','')\n",
    "            tmp[11]=pd.to_datetime(tmp[9])+np.timedelta64(tmp[11],'D')\n",
    "\n",
    "            tmp_.append(tmp[11])\n",
    "\n",
    "\n",
    "            tmp_.append(tmp[16])\n",
    "            \n",
    "        elif tmp[10]==u'Pending' or tmp[10]==u'Waitlist' and tmp[11][0]=='(' and tmp[11][1]!='D':\n",
    "            tmp_.append(pd.to_datetime('1970-01-01'))\n",
    "            tmp_.append(tmp[10])\n",
    "            tmp[12]=tmp[12].split(': ')[1]\n",
    "            tmp[12]=tmp[12].replace(')','')\n",
    "            tmp[12]=pd.to_datetime(tmp[9])+np.timedelta64(tmp[12],'D')\n",
    "\n",
    "            tmp_.append(tmp[12])\n",
    "\n",
    "\n",
    "            tmp_.append(tmp[16])\n",
    "            \n",
    "            \n",
    "        \n",
    "        elif tmp[10][0:3]==u'INT':\n",
    "            int_time=tmp[10].split(': ')[1]\n",
    "            tmp_.append(pd.to_datetime(int_time))\n",
    "            tmp_.append(tmp[11])\n",
    "            if tmp[12][0:2]=='(D':\n",
    "                tmp[12]=tmp[12].split(': ')[1]\n",
    "                tmp[12]=tmp[12].replace(')','')\n",
    "                tmp[12]=pd.to_datetime(tmp[9])+np.timedelta64(tmp[12],'D')\n",
    "\n",
    "                tmp_.append(tmp[12])\n",
    "            else:\n",
    "                tmp[12]=tmp[12].replace('(','').replace(')','')\n",
    "                tmp[12]=pd.to_datetime(tmp[12])\n",
    "                tmp_.append(tmp[12])\n",
    "\n",
    "    #         tmp[14]=tmp[14].split(' ')[0]\n",
    "    #         tmp[14]=pd.to_datetime(tmp[14],format='%m/%d/%y')\n",
    "    #         tmp_.append(tmp[14])\n",
    "\n",
    "            tmp_.append(tmp[17])\n",
    "        else:\n",
    "\n",
    "            tmp_.append(pd.to_datetime('1970-01-01'))\n",
    "            tmp_.append(tmp[10])\n",
    "            tmp[11]=tmp[11].replace('(','').replace(')','')\n",
    "            \n",
    "            tmp[11]=pd.to_datetime(tmp[11])\n",
    "            tmp_.append(tmp[11])\n",
    "\n",
    "    #         tmp[13]=tmp[13].split(' ')[0]\n",
    "    #         tmp[13]=pd.to_datetime(tmp[13],format='%m/%d/%y')\n",
    "    #         tmp_.append(tmp[13])\n",
    "\n",
    "\n",
    "            tmp_.append(tmp[17])\n",
    "\n",
    "\n",
    "        total.append(tmp_)\n",
    "    df=pd.DataFrame(total,columns=['program','full_part','user_name','ugpa','gre_q',\n",
    "                              'gre_v','gre_aw','submitted','interview','result','update_date','note'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def execute_sql(page_number):\n",
    "    try:\n",
    "        engine=create_engine(\"mysql+pymysql://liyuefan:1994050306@localhost/gtja_intern?charset=utf8\")\n",
    "        df=execute(page_number)\n",
    "#         df.to_sql('quant_net_data',index=False,if_exists='append')\n",
    "        print 'page %s succeeded'%page_number\n",
    "    except:\n",
    "        print 'page %s failed'%page_number\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loop_execute():\n",
    "    page_range=264\n",
    "    for i in range(1,page_range+1):\n",
    "        execute_sql(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent process 71369.\n",
      "Waiting for all subprocesses done...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liyuefan/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 174 of the file /Users/liyuefan/anaconda2/lib/python2.7/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n",
      "/Users/liyuefan/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 174 of the file /Users/liyuefan/anaconda2/lib/python2.7/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n",
      "/Users/liyuefan/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 174 of the file /Users/liyuefan/anaconda2/lib/python2.7/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page 4 succeeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liyuefan/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 174 of the file /Users/liyuefan/anaconda2/lib/python2.7/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page 2 succeeded\n",
      "page 3 succeeded\n",
      "page 1 succeeded\n",
      "page 6 succeeded\n",
      "page 5 succeeded\n",
      "page 8 succeeded\n",
      "page 7 succeeded\n",
      "page 10 failed\n",
      "page 12 succeeded\n",
      "page 9 succeeded\n",
      "page 11 succeeded\n",
      "page 13 succeeded\n",
      "page 14 succeeded\n",
      "page 15 succeeded\n",
      "page 16 succeeded\n",
      "page 18 succeeded\n",
      "page 19 succeeded\n",
      "page 20 succeeded\n",
      "page 17 succeeded\n",
      "page 21 succeeded\n",
      "page 24 succeeded\n",
      "page 23 succeeded\n",
      "page 22 succeeded\n",
      "page 25 succeeded\n",
      "page 27 succeeded\n",
      "page 28 succeeded\n",
      "page 26 succeeded\n",
      "page 29 succeeded\n",
      "page 31 succeeded\n",
      "page 32 succeeded\n",
      "page 30 succeeded\n",
      "page 33 succeeded\n",
      "page 34 succeeded\n",
      "page 35 succeeded\n",
      "page 36 succeeded\n",
      "page 39 succeeded\n",
      "page 38 succeeded\n",
      "page 37 succeeded\n",
      "page 40 succeeded\n",
      "page 41 succeeded\n",
      "page 43 succeeded\n",
      "page 42 succeeded\n",
      "page 44 succeeded\n",
      "page 45 succeeded\n",
      "page 46 failed\n",
      "page 47 succeeded\n",
      "page 48 succeeded\n",
      "page 50 succeeded\n",
      "page 51 succeeded\n",
      "page 49 succeeded\n",
      "page 52 succeeded\n",
      "page 53 succeeded\n",
      "page 54 succeeded\n",
      "page 56 failed\n",
      "page 55 succeeded\n",
      "page 57 succeeded\n",
      "page 58 succeeded\n",
      "page 59 succeeded\n",
      "page 60 succeeded\n",
      "page 61 succeeded\n",
      "page 62 succeeded\n",
      "page 63 succeeded\n",
      "page 64 succeeded\n",
      "page 65 succeeded\n",
      "page 67 succeeded\n",
      "page 68 failed\n",
      "page 69 succeeded\n",
      "page 70 succeeded\n",
      "page 71 succeeded\n",
      "page 72 succeeded\n",
      "page 73 succeeded\n",
      "page 74 succeeded\n",
      "page 75 succeeded\n",
      "page 76 succeeded\n",
      "page 77 succeeded\n",
      "page 78 succeeded\n",
      "page 79 succeeded\n",
      "page 80 succeeded\n",
      "page 81 succeeded\n",
      "page 82 succeeded\n",
      "page 83 succeeded\n",
      "page 84 succeeded\n",
      "page 86 succeeded\n",
      "page 85 succeeded\n",
      "page 87 succeeded\n",
      "page 88 succeeded\n",
      "page 89 succeeded\n",
      "page 90 succeeded\n",
      "page 91 succeeded\n",
      "page 92 succeeded\n",
      "page 93 succeeded\n",
      "page 66 succeeded\n",
      "page 94 succeeded\n",
      "page 95 succeeded\n",
      "page 96 succeeded\n",
      "page 97 succeeded\n",
      "page 98 succeeded\n",
      "page 99 succeeded\n",
      "page 100 succeeded\n",
      "page 101 succeeded\n",
      "page 102 succeeded\n",
      "page 103 succeeded\n",
      "page 104 succeeded\n",
      "page 105 failed\n",
      "page 107 succeeded\n",
      "page 108 succeeded\n",
      "page 109 succeeded\n",
      "page 106 succeeded\n",
      "page 110 succeeded\n",
      "page 112 succeeded\n",
      "page 111 succeeded\n",
      "page 114 succeeded\n",
      "page 113 succeeded\n",
      "page 116 succeeded\n",
      "page 115 succeeded\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    print('Parent process %s.' % os.getpid())\n",
    "    p = Pool(4)\n",
    "    for i in range(1,265):\n",
    "        p.apply_async(execute_sql, args=(i,))\n",
    "    print('Waiting for all subprocesses done...')\n",
    "    p.close()\n",
    "    p.join()\n",
    "    print('All subprocesses done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
