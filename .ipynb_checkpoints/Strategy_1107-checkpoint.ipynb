{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year\n",
      "2008    1221.20\n",
      "2009    1902.40\n",
      "2010    3386.75\n",
      "2011    1960.60\n",
      "2012     709.35\n",
      "2013    1016.20\n",
      "2014    2258.50\n",
      "2015    1543.60\n",
      "2016    2229.90\n",
      "Name: quantile_high, dtype: float64\n",
      "Year\n",
      "2008    -927.80\n",
      "2009   -1813.00\n",
      "2010   -3346.50\n",
      "2011   -2144.20\n",
      "2012    -633.25\n",
      "2013   -1088.00\n",
      "2014   -2310.00\n",
      "2015   -1674.40\n",
      "2016   -2268.40\n",
      "Name: quantile_low, dtype: float64\n",
      "        turn_over_rate\n",
      "Year                  \n",
      "2007.0      455.477048\n",
      "2008.0      333.563796\n",
      "2009.0      423.163767\n",
      "2010.0      695.504146\n",
      "2011.0      415.162285\n",
      "2012.0      218.709128\n",
      "2013.0      211.254980\n",
      "2014.0      514.509253\n",
      "2015.0      398.693804\n",
      "2016.0      434.399990\n",
      "看多交易最大回撤： 0.0555721861109\n",
      "看多交易累计收益：  0.158545150519\n",
      "看多交易单次长度：  [3, 1, 5, 10, 5, 7, 12, 13, 3, 16, 47]\n",
      "看空交易最大回撤： 0.064083693916\n",
      "看空交易累计收益：  0.309650138399\n",
      "看空交易单次长度：  [1, 29, 6, 2, 34, 5, 7, 36, 12, 5, 9, 9]\n"
     ]
    }
   ],
   "source": [
    "#coding:utf8\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from WindPy import *\n",
    "import copy\n",
    "from sqlalchemy import create_engine\n",
    "import pymysql\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def collect_data(category,engine):\n",
    "    position_data=pd.read_sql_query(\"select distinct * from gtja_intern.zn_volume_data where company_name_2 in ('永安期货','新湖期货','浙商期货') \"\n",
    "                                    \"or company_name_3 in ('永安期货','新湖期货','浙商期货') and category='%s'\"%category,engine)\n",
    "    date_unique=pd.read_sql(\"select distinct update_date from gtja_intern.%s_volume_data\"%category,engine)\n",
    "    position_data=position_data.iloc[:,4:]\n",
    "    position_data['update_date']=pd.to_datetime(position_data['update_date'])\n",
    "    date_unique['update_date']=pd.to_datetime(date_unique['update_date'])\n",
    "    index_data=pd.read_csv(\"%sFI.csv\"%category.upper(),header=0,encoding='gbk')\n",
    "    index_data['update_date']=pd.to_datetime(index_data['update_date'])\n",
    "    index_data=index_data.sort('update_date')\n",
    "    return position_data,date_unique,index_data\n",
    "\n",
    "\n",
    "def stop_loss(data,threshold,stop_order):\n",
    "    all_cnt=[]\n",
    "    date_separator=[]\n",
    "    cnt=0\n",
    "    i_list=[]\n",
    "    date_start=[]\n",
    "    record_list=[]\n",
    "    if stop_order=='non_trailing':\n",
    "        for i in range(len(data)):\n",
    "            print float(i)/len(data),'\\r',\n",
    "            temp=data.iloc[i,:]\n",
    "\n",
    "            if i>=1 and temp['out']>0 and cnt==0 and data.iloc[i-1,:]['out']<=0:\n",
    "                date_start.append(temp['update_date'])\n",
    "                stop_price=temp['max5']\n",
    "                i_list.append(i)\n",
    "                cnt+=1\n",
    "                record_list.append(1)\n",
    "\n",
    "\n",
    "            elif temp['out']>0 and temp['high']<stop_price and cnt!=0:\n",
    "                cnt+=1\n",
    "                i_list.append(i)\n",
    "                record_list.append(2)\n",
    "            elif temp['out']>0 and temp['high']>=stop_price and cnt!=0:\n",
    "\n",
    "                all_cnt.append(cnt)\n",
    "                date_separator.append(pd.to_datetime(temp['update_date']))\n",
    "\n",
    "                cnt=0\n",
    "                record_list.append(3)\n",
    "                temp['return_rate']=-np.max((np.log(stop_price)-np.log(temp['open']),temp['return_rate']))\n",
    "\n",
    "            elif temp['out']==0 and cnt!=0:\n",
    "                all_cnt.append(cnt)\n",
    "                date_separator.append(pd.to_datetime(temp['update_date']))\n",
    "\n",
    "                cnt=0\n",
    "                record_list.append(4)\n",
    "            else:\n",
    "                cnt=0\n",
    "                record_list.append(5)\n",
    "\n",
    "        data['record']=record_list\n",
    "        signal_count_2=data[data['record']<=2]\n",
    "\n",
    "\n",
    "\n",
    "def execute(category,engine,stop_order):\n",
    "    position_data,date_unique,index_data=collect_data(category,engine)\n",
    "\n",
    "    ##calculate ADX\n",
    "    open_yes=[np.nan]\n",
    "    open_yes.extend(index_data['open'][:-1])\n",
    "    index_data['open_yes']=open_yes\n",
    "    high_yes=[np.nan]\n",
    "    high_yes.extend(index_data['high'][:-1])\n",
    "    index_data['high_yes']=high_yes\n",
    "    low_yes=[np.nan]\n",
    "    low_yes.extend(index_data['low'][:-1])\n",
    "    index_data['low_yes']=low_yes\n",
    "    close_yes=[np.nan]\n",
    "    close_yes.extend(index_data['close'][:-1])\n",
    "    index_data['close_yes']=close_yes\n",
    "    index_data['DM+']=index_data['high']-index_data['high_yes']\n",
    "    index_data['DM-']=index_data['low_yes']-index_data['low']\n",
    "    index_data['TR']=map(lambda x,y,z:np.max((x,y,z)),np.abs(index_data['high']-index_data['low']),np.abs(index_data['high']-index_data['close_yes']),\n",
    "                       np.abs(index_data['low']-index_data['close_yes']))\n",
    "    index_data['DI+']=pd.rolling_mean(index_data['DM+'],14)/pd.rolling_mean(index_data['TR'],14)*100\n",
    "    index_data['DI-']=pd.rolling_mean(index_data['DM-'],14)/pd.rolling_mean(index_data['TR'],14)*100\n",
    "    index_data['ADX']=pd.rolling_mean((index_data['DI+']-index_data['DI-'])/(index_data['DI+']+index_data['DI-'])*100.,14)\n",
    "\n",
    "    ##calculate moving average to find the trend\n",
    "    index_data['MA5']=pd.rolling_mean(index_data['open'],30)\n",
    "    index_data['MA10']=pd.rolling_mean(index_data['open'],60)\n",
    "\n",
    "    ##calculate moving min of last 5 days\n",
    "    index_data['min5']=pd.rolling_min(index_data['low'],5)\n",
    "    index_data['max5']=pd.rolling_max(index_data['high'],5)\n",
    "\n",
    "    index_data.index=[index_data['update_date']]\n",
    "    index_data['trend']=index_data['MA5']-index_data['MA10']\n",
    "    trend_list=[np.nan]\n",
    "    trend_list.extend(index_data['trend'][:-1])\n",
    "    min5_list=[np.nan]\n",
    "    min5_list.extend(index_data['min5'][:-1])\n",
    "    index_data['trend']=trend_list\n",
    "    index_data['min5']=min5_list\n",
    "\n",
    "\n",
    "    max5_list=[np.nan]\n",
    "    max5_list.extend(index_data['max5'][:-1])\n",
    "    index_data['max5']=max5_list\n",
    "\n",
    "\n",
    "    #a new table to transpose the whole matrix\n",
    "    position_data_org=pd.DataFrame(columns=['company_name','position','position_chg','update_date','contract'])\n",
    "    temp=position_data[['company_name_2','hold_vol_buy','hold_vol_buy_chg','update_date','contract']]\n",
    "    temp=temp.rename(columns={'company_name_2':'company_name','hold_vol_buy':'position','hold_vol_buy_chg':'position_chg'})\n",
    "    position_data_org=position_data_org.append(temp)\n",
    "    temp=position_data[['company_name_3','hold_vol_sell','hold_vol_sell_chg','update_date','contract']]\n",
    "    temp=temp.rename(columns={'company_name_3':'company_name','hold_vol_sell':'position','hold_vol_sell_chg':'position_chg'})\n",
    "    temp['position']=-1*temp['position']\n",
    "    position_data_org=position_data_org.append(temp)\n",
    "\n",
    "    position_investor_zhejiang=pd.DataFrame(position_data_org.groupby(['update_date','company_name']).position.sum())\n",
    "    position_investor_zhejiang=position_investor_zhejiang.reset_index()\n",
    "    position_investor_zhejiang_1=position_investor_zhejiang[position_investor_zhejiang['company_name'].apply(lambda x:x.replace(' ',''))==u'新湖期货']\n",
    "    position_investor_zhejiang_1.index=position_investor_zhejiang_1['update_date']\n",
    "    position_investor_zhejiang_2=position_investor_zhejiang[position_investor_zhejiang['company_name'].apply(lambda x:x.replace(' ',''))==u'浙商期货']\n",
    "    position_investor_zhejiang_2.index=position_investor_zhejiang_2['update_date']\n",
    "    position_investor_zhejiang_3=position_investor_zhejiang[position_investor_zhejiang['company_name'].apply(lambda x:x.replace(' ',''))==u'永安期货']\n",
    "    position_investor_zhejiang_3.index=position_investor_zhejiang_3['update_date']\n",
    "\n",
    "    position_zhejiang=pd.concat([position_investor_zhejiang_1,position_investor_zhejiang_2,position_investor_zhejiang_3],axis=0)\n",
    "\n",
    "    position_zhejiang=position_zhejiang.drop('update_date',axis=1)\n",
    "    position_zhejiang=position_zhejiang.reset_index()\n",
    "    position_zhejiang['update_date']=pd.to_datetime(position_zhejiang['update_date'])\n",
    "    position_zhejiang=pd.merge(position_zhejiang,date_unique,on='update_date',how='outer')\n",
    "    position_zhejiang_lag=pd.DataFrame()\n",
    "    for i, j in position_zhejiang.groupby(['company_name']):\n",
    "        j=j.sort(['update_date'])\n",
    "        t=pd.DataFrame()\n",
    "        t['update_date']=j['update_date'][1:]\n",
    "        t['company_name']=i\n",
    "        t['position']=j['position'][:-1]\n",
    "        position_zhejiang_lag=position_zhejiang_lag.append(t)\n",
    "    position_zhejiang_lag.index=[position_zhejiang_lag['update_date']]\n",
    "\n",
    "    position_zhejiang_lag=position_zhejiang_lag.drop('update_date',axis=1)\n",
    "    index_data=index_data.drop('update_date',axis=1)\n",
    "    index_data=index_data.reset_index()\n",
    "    position_zhejiang_lag=position_zhejiang_lag.reset_index()\n",
    "    merged_data=pd.merge(index_data,position_zhejiang_lag,on='update_date',how='outer')\n",
    "\n",
    "    #计算昨天与前天相比的净头寸变化量\n",
    "    total_merged=pd.DataFrame()\n",
    "    for i, j in merged_data.groupby('company_name'):\n",
    "        j=j.sort('update_date')\n",
    "        temp_list=[np.nan]\n",
    "        temp_list.extend(list(j['position'][:-1]))\n",
    "\n",
    "        j['position_lag']=temp_list\n",
    "        j['position_diff']=j['position']-j['position_lag']\n",
    "\n",
    "        total_merged=total_merged.append(j)\n",
    "\n",
    "    position_diff_lag=[np.nan]\n",
    "    position_diff_lag.extend(total_merged['position_diff'][:-1])\n",
    "    total_merged['position_diff_lag']=position_diff_lag\n",
    "\n",
    "    total_merged=total_merged.dropna(subset=['trend'],axis=0)\n",
    "    # total_merged_inv=total_merged[total_merged['position_diff']>=total_merged['position_diff'].quantile(0.975)]\n",
    "\n",
    "\n",
    "    total_merged['Year']=total_merged['update_date'].apply(lambda x:x.year)\n",
    "    quantile_merged=pd.DataFrame(total_merged.groupby(['Year']).position_diff.quantile(0.95))\n",
    "    quantile_merged=quantile_merged.rename(columns={'position_diff':'quantile_high'})\n",
    "    print quantile_merged['quantile_high']\n",
    "    quantile_merged.reset_index(inplace=True)\n",
    "    total_merged.index=[total_merged['Year']]\n",
    "    total_merged=pd.merge(total_merged,quantile_merged,on='Year',how='left')\n",
    "    total_merged_inv=total_merged[total_merged['position_diff']>=total_merged['position_all']*0.005]\n",
    "\n",
    "    ##用ADX来检验趋势强弱\n",
    "    #total_merged_inv=total_merged_inv[total_merged_inv['ADX']>=25]\n",
    "\n",
    "    total_merged_inv['trend']=total_merged_inv['trend'].apply(lambda x:1 if x>0 else -1)\n",
    "\n",
    "    r_long=total_merged_inv[total_merged_inv['trend']==1]\n",
    "    r_long['return']=(r_long['close']-r_long['open'])/r_long['open']\n",
    "\n",
    "    plt.figure(figsize=(20,15))\n",
    "    plt.hist(total_merged['position'].dropna(),bins=50);\n",
    "    plt.title('histogram of position')\n",
    "    plt.show()\n",
    "\n",
    "    # total_merged_inv=total_merged[total_merged['position_diff']<=total_merged['position_diff'].quantile(0.025)]\n",
    "    quantile_merged=pd.DataFrame(total_merged.groupby(['Year']).position_diff.quantile(0.05))\n",
    "    quantile_merged=quantile_merged.rename(columns={'position_diff':'quantile_low'})\n",
    "    print quantile_merged['quantile_low']\n",
    "    quantile_merged.reset_index(inplace=True)\n",
    "    total_merged.index=[total_merged['Year']]\n",
    "    total_merged=pd.merge(total_merged,quantile_merged,on='Year',how='left')\n",
    "    total_merged_inv=total_merged[total_merged['position_diff']<=-total_merged['position_all']*0.005]\n",
    "    #total_merged_inv=total_merged_inv[total_merged_inv['ADX']>=25]\n",
    "    total_merged_inv['trend']=total_merged_inv['trend'].apply(lambda x:1 if x>0 else -1)\n",
    "    r_short=total_merged_inv[total_merged_inv['trend']==-1]\n",
    "    r_short['return']=-(r_short['close']-r_short['open'])/r_short['open']\n",
    "\n",
    "    plt.figure(figsize=(40,30))\n",
    "    plt.plot(position_investor_zhejiang_1.index,position_investor_zhejiang_1['position'],label=u'XinHu')\n",
    "    plt.plot(position_investor_zhejiang_2.index,position_investor_zhejiang_2['position'],label=u'ZheShang')\n",
    "    plt.plot(position_investor_zhejiang_3.index,position_investor_zhejiang_3['position'],label=u'YongAn')\n",
    "    plt.title('position of three commodity traders')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    r_long=r_long.sort('update_date')\n",
    "    r_long=r_long.rename(columns={'return':'return_rate'})\n",
    "    r_long_1=pd.DataFrame(r_long.groupby('update_date').return_rate.sum())\n",
    "    r_long_1=r_long_1.reset_index()\n",
    "    r_long_1['accu_return_rate']=100*(1+r_long_1.iloc[0,:]['return_rate'])\n",
    "\n",
    "    for i in range(1,len(r_long_1)):\n",
    "        r_long_1.iat[i,2]=r_long_1.iat[i-1,2]*(r_long_1.iat[i,1]+1)\n",
    "\n",
    "    r_long_1.index=r_long_1['update_date']\n",
    "    plt.figure(figsize=(15,10))\n",
    "    plt.subplot(2,1,1)\n",
    "\n",
    "    plt.plot(r_long_1.index,r_long_1['accu_return_rate'])\n",
    "    plt.title('long accu return')\n",
    "    plt.subplot(2,1,2)\n",
    "\n",
    "    plt.plot(r_long_1.index,r_long_1['return_rate'])\n",
    "    plt.title('long_return')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    r_short=r_short.sort('update_date')\n",
    "    r_short=r_short.rename(columns={'return':'return_rate'})\n",
    "    r_short_1=pd.DataFrame(r_short.groupby('update_date').return_rate.sum())\n",
    "    r_short_1=r_short_1.reset_index()\n",
    "    r_short_1['accu_return_rate']=100*(1+r_short_1.iloc[0,:]['return_rate'])\n",
    "\n",
    "    for i in range(1,len(r_short_1)):\n",
    "        r_short_1.iat[i,2]=r_short_1.iat[i-1,2]*(r_short_1.iat[i,1]+1)\n",
    "\n",
    "    r_short_1.index=r_short_1['update_date']\n",
    "\n",
    "    plt.figure(figsize=(15,10))\n",
    "    plt.subplot(2,1,1)\n",
    "\n",
    "    plt.plot(r_short_1.index,r_short_1['accu_return_rate'])\n",
    "    plt.title('short accu return')\n",
    "\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(r_short_1.index,r_short_1['return_rate'])\n",
    "    plt.title('short return')\n",
    "    plt.show()\n",
    "\n",
    "    index_data.index=[index_data['update_date']]\n",
    "\n",
    "    position_turn_over=pd.read_csv('C:/Users/liyuefanxxl/Documents/gtja/%s_turn_over.csv'%(category[0].upper()),encoding='gbk')\n",
    "    position_turn_over['update_date']=pd.to_datetime(position_turn_over['update_date'])\n",
    "    position_turn_over['update_date_2']=np.nan\n",
    "    position_turn_over['update_date_2'][:-1]=position_turn_over['update_date'][1:]\n",
    "    position_turn_over=position_turn_over.drop(\"update_date\",axis=1)\n",
    "    position_turn_over=position_turn_over.rename(columns={'update_date_2':'update_date'})\n",
    "\n",
    "    position_turn_over=position_turn_over.dropna(subset=['turn_over_rate'],axis=0)\n",
    "    position_turn_over['turn_over_rate']=abs(position_turn_over['turn_over_rate'])\n",
    "\n",
    "    position_turn_over['Year']=position_turn_over['update_date'].apply(lambda x: x.year)\n",
    "    turn_over_quantile=pd.DataFrame(position_turn_over.groupby('Year').turn_over_rate.quantile(0.95))\n",
    "    print turn_over_quantile\n",
    "    turn_over_quantile.reset_index(inplace=True)\n",
    "    turn_over_quantile=turn_over_quantile.rename(columns={'turn_over_rate':'quantile'})\n",
    "    position_turn_over=position_turn_over.merge(turn_over_quantile,on='Year',how='left')\n",
    "\n",
    "    position_clear_signal=position_turn_over[position_turn_over['turn_over_rate']>=position_turn_over['quantile']]\n",
    "    position_clear_signal['clear_signal']=-1\n",
    "\n",
    "    position_clear_signal.index=[position_clear_signal['update_date']]\n",
    "\n",
    "\n",
    "#################################################################################\n",
    "    r_long_1['invest_signal']=1\n",
    "    r_long_1=r_long_1[pd.to_datetime('2011-01-01'):]\n",
    "    r_long_1=pd.concat([r_long_1,position_clear_signal[['clear_signal']]],axis=1,join='outer')\n",
    "\n",
    "    r_long_1['invest_signal']=r_long_1['invest_signal'].fillna(r_long_1['clear_signal'])\n",
    "\n",
    "\n",
    "    data_long=pd.concat([r_long_1[['invest_signal']],index_data],axis=1,join='outer')\n",
    "\n",
    "\n",
    "    data_long['invest_signal']=data_long['invest_signal'].fillna(method='ffill')\n",
    "\n",
    "    data_long['invest_signal']=pd.rolling_mean(data_long['invest_signal'],2)\n",
    "\n",
    "    data_long=data_long.dropna(subset=['invest_signal'],axis=0)\n",
    "\n",
    "    data_long_filtered=data_long[data_long['invest_signal']>=0]\n",
    "\n",
    "    data_long_filtered['return_rate']=np.nan\n",
    "    data_long_filtered['return_rate'][1:]=np.diff(np.log(data_long_filtered['open']))\n",
    "\n",
    "\n",
    "    date_unique_long=pd.DataFrame(date_unique[date_unique['update_date']>=min(data_long_filtered.index)]['update_date'])\n",
    "\n",
    "    data_1=index_data[pd.to_datetime('2011-01-01'):]\n",
    "\n",
    "    open_price=pd.read_csv(\"%s_5min_price.csv\"%(category[0].upper()),encoding='gbk')\n",
    "\n",
    "    open_price['update_date']=pd.to_datetime(open_price['update_date'])\n",
    "\n",
    "    open_price['Date']=open_price['update_date'].apply(lambda x:pd.to_datetime(str(x.date())))\n",
    "\n",
    "    open_price=open_price[open_price['update_date'].apply(lambda x:x.hour>=9 and x.minute>0)]\n",
    "\n",
    "    open_price_1=pd.DataFrame(open_price.groupby(\"Date\").update_date.min())\n",
    "\n",
    "    open_price_1.reset_index(inplace=True)\n",
    "\n",
    "    open_price_filtered=pd.merge(open_price,open_price_1[['update_date']],on='update_date',how='inner')\n",
    "\n",
    "    open_price_filtered.index=[open_price_filtered['Date']]\n",
    "    return_rate=[np.nan]\n",
    "    return_rate.extend(np.diff(np.log(open_price_filtered['open'])))\n",
    "    open_price_filtered['return_rate']=return_rate\n",
    "\n",
    "\n",
    "    date_unique_long.index=[date_unique_long['update_date']]\n",
    "\n",
    "\n",
    "\n",
    "    return_cal=pd.concat([open_price_filtered[['open','update_date','return_rate']],data_long_filtered[['volume','high','low','invest_signal','min5','max5']]],axis=1,join='inner')\n",
    "\n",
    "    return_cal['invest_signal']=pd.rolling_mean(return_cal['invest_signal'],2)\n",
    "\n",
    "    return_cal['invest_signal']=return_cal['invest_signal'].fillna(0.5)\n",
    "\n",
    "\n",
    "\n",
    "    return_cal=return_cal[return_cal['invest_signal']!=0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return_cal=return_cal.drop(['update_date'],axis=1)\n",
    "    return_cal['out']=1\n",
    "    signal_count=pd.concat([date_unique_long,return_cal],axis=1,join='outer')\n",
    "\n",
    "    signal_count['out']=signal_count['out'].fillna(0)\n",
    "\n",
    "    signal_count.reset_index(inplace=True)\n",
    "    signal_count['update_date']=signal_count['update_date'].fillna(signal_count['index'])\n",
    "    signal_count.index=[signal_count['update_date']]\n",
    "\n",
    "    all_cnt=[]\n",
    "    date_separator=[]\n",
    "    cnt=0\n",
    "    i_list=[]\n",
    "    date_start=[]\n",
    "    record_list=[]\n",
    "    if stop_order=='non_trailing':\n",
    "        for i in range(len(signal_count)):\n",
    "            print float(i)/len(signal_count),'\\r',\n",
    "            temp=signal_count.iloc[i,:]\n",
    "\n",
    "            if i>=1 and temp['out']>0 and cnt==0 and signal_count.iloc[i-1,:]['out']<=0:\n",
    "                date_start.append(temp['update_date'])\n",
    "                stop_price=temp['min5']\n",
    "                i_list.append(i)\n",
    "                cnt+=1\n",
    "                record_list.append(1)\n",
    "\n",
    "\n",
    "            elif temp['out']>0 and temp['low']>stop_price and cnt!=0:\n",
    "                cnt+=1\n",
    "                i_list.append(i)\n",
    "                record_list.append(2)\n",
    "            elif temp['out']>0 and temp['low']<=stop_price and cnt!=0:\n",
    "\n",
    "                all_cnt.append(cnt)\n",
    "                date_separator.append(pd.to_datetime(temp['update_date']))\n",
    "\n",
    "                cnt=0\n",
    "                record_list.append(3)\n",
    "                temp['return_rate']=np.min((np.log(stop_price)-np.log(temp['open']),temp['return_rate']))\n",
    "\n",
    "            elif temp['out']==0 and cnt!=0:\n",
    "                all_cnt.append(cnt)\n",
    "\n",
    "                date_separator.append(pd.to_datetime(temp['update_date']))\n",
    "                cnt=0\n",
    "                record_list.append(4)\n",
    "\n",
    "            else:\n",
    "                cnt=0\n",
    "                record_list.append(5)\n",
    "\n",
    "        signal_count['record']=record_list\n",
    "        signal_count_2=signal_count[signal_count['record']<=2]\n",
    "\n",
    "\n",
    "\n",
    "    if stop_order=='trailing':\n",
    "        for i in range(len(signal_count)):\n",
    "            print float(i)/len(signal_count),'\\r',\n",
    "            temp=signal_count.iloc[i,:]\n",
    "\n",
    "            if i>=1 and temp['out']>0 and cnt==0 and signal_count.iloc[i-1,:]['out']<=0:\n",
    "                date_start.append(temp['update_date'])\n",
    "                stop_price=temp['min5']\n",
    "                i_list.append(i)\n",
    "                cnt+=1\n",
    "                record_list.append(1)\n",
    "\n",
    "\n",
    "            elif temp['out']>0 and temp['low']>0.98*temp['open'] and cnt!=0:\n",
    "                cnt+=1\n",
    "                i_list.append(i)\n",
    "                record_list.append(2)\n",
    "            elif temp['out']>0 and temp['low']<=0.98*temp['open'] and cnt!=0:\n",
    "\n",
    "                all_cnt.append(cnt)\n",
    "                date_separator.append(pd.to_datetime(temp['update_date']))\n",
    "\n",
    "                cnt=0\n",
    "                record_list.append(3)\n",
    "                temp['return_rate']=(np.log(temp['low'])-np.log(temp['open']))\n",
    "\n",
    "            elif temp['out']==0 and cnt!=0:\n",
    "                all_cnt.append(cnt)\n",
    "\n",
    "                date_separator.append(pd.to_datetime(temp['update_date']))\n",
    "                cnt=0\n",
    "                record_list.append(4)\n",
    "\n",
    "            else:\n",
    "                cnt=0\n",
    "                record_list.append(5)\n",
    "\n",
    "        signal_count['record']=record_list\n",
    "        signal_count_2=signal_count[signal_count['record']<=2]\n",
    "\n",
    "\n",
    "\n",
    "    accu_sum=0\n",
    "    accu_list=[]\n",
    "    max_draw=[np.nan]\n",
    "    for item in signal_count_2['return_rate']:\n",
    "        if np.isnan(item):\n",
    "            item=0\n",
    "        else:\n",
    "            item=item\n",
    "        accu_sum+=item\n",
    "        try:\n",
    "            draw_benchmark=np.max(accu_list)\n",
    "            max_draw.append(draw_benchmark-accu_sum)\n",
    "        except:\n",
    "            pass\n",
    "        accu_list.append(accu_sum)\n",
    "\n",
    "    signal_count_2['accu_return']=accu_list\n",
    "    signal_count_2['max_draw']=max_draw\n",
    "\n",
    "    signal_count_2.to_csv(\"signal_count_long.csv\",index=False,encoding='gbk')\n",
    "    plt.figure(figsize=(30,20))\n",
    "    plt.plot(signal_count_2.index,signal_count_2['accu_return'])\n",
    "\n",
    "\n",
    "    fig=plt.figure(facecolor='none',figsize=(15,10))\n",
    "    #date_separator=list(set(data_short_filtered[data_short_filtered['invest_signal']==1].index+np.timedelta64(1,'D'))-set(data_short_filtered[data_short_filtered['invest_signal']==1].index))\n",
    "\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.plot(data_1.index,data_1['open'])\n",
    "    ax.vlines(date_separator,10000,20000,colors='red')\n",
    "    ax.vlines(signal_count_2.index,10000,20000,colors='yellow',linestyles='dashed')\n",
    "    plt.show()\n",
    "    print u'看多交易最大回撤：',np.max(signal_count_2['max_draw'])\n",
    "    print u'看多交易累计收益： ', signal_count_2['return_rate'].sum()\n",
    "    print u'看多交易单次长度： ', filter(lambda x:x!=0,all_cnt)\n",
    "\n",
    "\n",
    "########################################################################################\n",
    "    r_short_1['invest_signal']=1\n",
    "    r_short_1=r_short_1[pd.to_datetime('2011-01-01'):]\n",
    "    r_short_1=pd.concat([r_short_1,position_clear_signal[['clear_signal']]],axis=1,join='outer')\n",
    "\n",
    "    r_short_1['invest_signal']=r_short_1['invest_signal'].fillna(r_short_1['clear_signal'])\n",
    "\n",
    "\n",
    "\n",
    "    data_short=pd.concat([r_short_1[['invest_signal']],index_data],axis=1,join='outer')\n",
    "\n",
    "\n",
    "    data_short['invest_signal']=data_short['invest_signal'].fillna(method='ffill')\n",
    "\n",
    "    data_short['invest_signal']=pd.rolling_mean(data_short['invest_signal'],2)\n",
    "\n",
    "    data_short=data_short.dropna(subset=['invest_signal'],axis=0)\n",
    "\n",
    "    data_short_filtered=data_short[data_short['invest_signal']>=0]\n",
    "\n",
    "    data_short_filtered['return_rate']=np.nan\n",
    "    data_short_filtered['return_rate'][1:]=np.diff(np.log(data_short_filtered['open']))\n",
    "\n",
    "\n",
    "    date_unique_short=pd.DataFrame(date_unique[date_unique['update_date']>=min(data_short_filtered.index)]['update_date'])\n",
    "\n",
    "    data_1=index_data[pd.to_datetime('2011-01-01'):]\n",
    "\n",
    "    open_price=pd.read_csv(\"%s_5min_price.csv\"%(category[0].upper()),encoding='gbk')\n",
    "\n",
    "    open_price['update_date']=pd.to_datetime(open_price['update_date'])\n",
    "\n",
    "    open_price['Date']=open_price['update_date'].apply(lambda x:pd.to_datetime(str(x.date())))\n",
    "\n",
    "    open_price=open_price[open_price['update_date'].apply(lambda x:x.hour>=9 and x.minute>0)]\n",
    "\n",
    "    open_price_1=pd.DataFrame(open_price.groupby(\"Date\").update_date.min())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    date_unique_short.index=[date_unique_short['update_date']]\n",
    "\n",
    "\n",
    "\n",
    "    open_price_1.reset_index(inplace=True)\n",
    "\n",
    "    open_price_filtered=pd.merge(open_price,open_price_1[['update_date']],on='update_date',how='inner')\n",
    "\n",
    "\n",
    "    return_rate=[np.nan]\n",
    "    return_rate.extend(-np.diff(np.log(open_price_filtered['open'])))\n",
    "    open_price_filtered['return_rate']=return_rate\n",
    "\n",
    "    open_price_filtered.index=[open_price_filtered['Date']]\n",
    "\n",
    "    return_cal=pd.concat([open_price_filtered[['open','update_date','return_rate']],data_short_filtered[['volume','high','low','invest_signal','min5','max5']]],axis=1,join='inner')\n",
    "\n",
    "    return_cal['invest_signal']=pd.rolling_mean(return_cal['invest_signal'],2)\n",
    "\n",
    "    return_cal['invest_signal']=return_cal['invest_signal'].fillna(0.5)\n",
    "\n",
    "\n",
    "\n",
    "    return_cal=return_cal[return_cal['invest_signal']!=0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return_cal=return_cal.drop(['update_date'],axis=1)\n",
    "    return_cal['out']=1\n",
    "    signal_count=pd.concat([date_unique_short,return_cal],axis=1,join='outer')\n",
    "\n",
    "    signal_count['out']=signal_count['out'].fillna(0)\n",
    "\n",
    "    signal_count.reset_index(inplace=True)\n",
    "    signal_count['update_date']=signal_count['update_date'].fillna(signal_count['index'])\n",
    "    signal_count.index=[signal_count['update_date']]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    all_cnt=[]\n",
    "    date_separator=[]\n",
    "    cnt=0\n",
    "    i_list=[]\n",
    "    date_start=[]\n",
    "    record_list=[]\n",
    "    if stop_order=='non_trailing':\n",
    "        for i in range(len(signal_count)):\n",
    "            print float(i)/len(signal_count),'\\r',\n",
    "            temp=signal_count.iloc[i,:]\n",
    "\n",
    "            if i>=1 and temp['out']>0 and cnt==0 and signal_count.iloc[i-1,:]['out']<=0:\n",
    "                date_start.append(temp['update_date'])\n",
    "                stop_price=temp['max5']\n",
    "                i_list.append(i)\n",
    "                cnt+=1\n",
    "                record_list.append(1)\n",
    "\n",
    "\n",
    "            elif temp['out']>0 and temp['high']<stop_price and cnt!=0:\n",
    "                cnt+=1\n",
    "                i_list.append(i)\n",
    "                record_list.append(2)\n",
    "            elif temp['out']>0 and temp['high']>=stop_price and cnt!=0:\n",
    "\n",
    "                all_cnt.append(cnt)\n",
    "                date_separator.append(pd.to_datetime(temp['update_date']))\n",
    "\n",
    "                cnt=0\n",
    "                record_list.append(3)\n",
    "                temp['return_rate']=-np.max((np.log(stop_price)-np.log(temp['open']),temp['return_rate']))\n",
    "\n",
    "            elif temp['out']==0 and cnt!=0:\n",
    "                all_cnt.append(cnt)\n",
    "                date_separator.append(pd.to_datetime(temp['update_date']))\n",
    "\n",
    "                cnt=0\n",
    "                record_list.append(4)\n",
    "            else:\n",
    "                cnt=0\n",
    "                record_list.append(5)\n",
    "\n",
    "        signal_count['record']=record_list\n",
    "        signal_count_2=signal_count[signal_count['record']<=2]\n",
    "\n",
    "    if stop_order=='trailing':\n",
    "        for i in range(len(signal_count)):\n",
    "            print float(i)/len(signal_count),'\\r',\n",
    "            temp=signal_count.iloc[i,:]\n",
    "\n",
    "            if i>=1 and temp['out']>0 and cnt==0 and signal_count.iloc[i-1,:]['out']<=0:\n",
    "                date_start.append(temp['update_date'])\n",
    "                stop_price=temp['max5']\n",
    "                i_list.append(i)\n",
    "                cnt+=1\n",
    "                record_list.append(1)\n",
    "\n",
    "\n",
    "            elif temp['out']>0 and temp['high']<1/0.98*temp['open'] and cnt!=0:\n",
    "                cnt+=1\n",
    "                i_list.append(i)\n",
    "                record_list.append(2)\n",
    "            elif temp['out']>0 and temp['high']>=1/0.98*temp['open'] and cnt!=0:\n",
    "\n",
    "                all_cnt.append(cnt)\n",
    "                date_separator.append(pd.to_datetime(temp['update_date']))\n",
    "\n",
    "                cnt=0\n",
    "                record_list.append(3)\n",
    "                temp['return_rate']=-(np.log(temp['high'])-np.log(temp['open']))\n",
    "\n",
    "            elif temp['out']==0 and cnt!=0:\n",
    "                all_cnt.append(cnt)\n",
    "                date_separator.append(pd.to_datetime(temp['update_date']))\n",
    "\n",
    "                cnt=0\n",
    "                record_list.append(4)\n",
    "            else:\n",
    "                cnt=0\n",
    "                record_list.append(5)\n",
    "\n",
    "        signal_count['record']=record_list\n",
    "        signal_count_2=signal_count[signal_count['record']<=2]\n",
    "\n",
    "\n",
    "    accu_sum=0\n",
    "    accu_list=[]\n",
    "    max_draw=[np.nan]\n",
    "    for item in signal_count_2['return_rate']:\n",
    "        if np.isnan(item):\n",
    "            item=0\n",
    "        else:\n",
    "            item=item\n",
    "        accu_sum+=item\n",
    "        try:\n",
    "            draw_benchmark=np.max(accu_list)\n",
    "            max_draw.append(draw_benchmark-accu_sum)\n",
    "        except:\n",
    "            pass\n",
    "        accu_list.append(accu_sum)\n",
    "\n",
    "    signal_count_2['accu_return']=accu_list\n",
    "    signal_count_2['max_draw']=max_draw\n",
    "\n",
    "    signal_count_2.to_csv(\"signal_count_short.csv\",index=False,encoding='gbk')\n",
    "    plt.figure(figsize=(30,20))\n",
    "    plt.plot(signal_count_2.index,signal_count_2['accu_return'])\n",
    "\n",
    "\n",
    "    fig=plt.figure(facecolor='none',figsize=(15,10))\n",
    "    #date_separator=list(set(data_short_filtered[data_short_filtered['invest_signal']==1].index+np.timedelta64(1,'D'))-set(data_short_filtered[data_short_filtered['invest_signal']==1].index))\n",
    "\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.plot(data_1.index,data_1['open'])\n",
    "    ax.vlines(date_separator,10000,20000,colors='red')\n",
    "    ax.vlines(signal_count_2.index,10000,20000,colors='green',linestyles='dashed')\n",
    "    plt.show()\n",
    "    print u'看空交易最大回撤：',np.max(signal_count_2['max_draw'])\n",
    "    print u'看空交易累计收益： ', signal_count_2['return_rate'].sum()\n",
    "    print u'看空交易单次长度： ', filter(lambda x:x!=0,all_cnt)\n",
    "\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    engine = create_engine(\"mysql+pymysql://liyuefan:1994050306@localhost/gtja_intern?charset=utf8\")\n",
    "    category='i'\n",
    "    stop_order='trailing'\n",
    "    execute(category,engine,stop_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
